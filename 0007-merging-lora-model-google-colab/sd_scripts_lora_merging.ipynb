{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gacon119/ArduinoR3/blob/master/0007-merging-lora-model-google-colab/sd_scripts_lora_merging.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBbeMmDZIA6w"
      },
      "source": [
        "[![Stable Diffusion merging LoRA models on Google colab](https://img.youtube.com/vi/_g0vLr-ekzg/sddefault.jpg)](https://www.youtube.com/watch?v=_g0vLr-ekzg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yw-ci4cMyqey"
      },
      "source": [
        "# Clone the sd-scripts repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3lqVkdVbnnXm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab259d8c-7486-4a50-87aa-4e775904da86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'sd-scripts'...\n",
            "remote: Enumerating objects: 9659, done.\u001b[K\n",
            "remote: Counting objects: 100% (25/25), done.\u001b[K\n",
            "remote: Compressing objects: 100% (20/20), done.\u001b[K\n",
            "remote: Total 9659 (delta 15), reused 5 (delta 5), pack-reused 9634 (from 2)\u001b[K\n",
            "Receiving objects: 100% (9659/9659), 11.62 MiB | 16.17 MiB/s, done.\n",
            "Resolving deltas: 100% (6933/6933), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/kohya-ss/sd-scripts.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHRoAzOuyybz"
      },
      "source": [
        "# Install PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3LOmZTVwjGzi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 525
        },
        "outputId": "3c61b875-033d-481b-f567-a6c171621e64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu116\n",
            "Collecting torch==1.13.1+cu116\n",
            "  Downloading https://download.pytorch.org/whl/cu116/torch-1.13.1%2Bcu116-cp311-cp311-linux_x86_64.whl (1977.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 GB\u001b[0m \u001b[31m882.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: Ignored the following yanked versions: 0.1.6, 0.1.7, 0.1.8, 0.1.9, 0.2.0, 0.2.1, 0.2.2, 0.2.2.post2, 0.2.2.post3, 0.15.0\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement torchvision==0.13.1+cu116 (from versions: 0.1.6, 0.2.0, 0.15.1, 0.15.2, 0.16.0, 0.16.1, 0.16.2, 0.17.0, 0.17.1, 0.17.2, 0.18.0, 0.18.1, 0.19.0, 0.19.1, 0.20.0, 0.20.1, 0.21.0, 0.22.0, 0.22.1)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torchvision==0.13.1+cu116\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting numpy==1.25\n",
            "  Downloading numpy-1.25.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Downloading numpy-1.25.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m80.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.25.0 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.25.0 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.25.0 which is incompatible.\n",
            "blosc2 3.4.0 requires numpy>=1.26, but you have numpy 1.25.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.25.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "d817d8fb029644cb9cda0806290cb824"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install torch==1.13.1+cu116 torchvision==0.13.1+cu116 --extra-index-url https://download.pytorch.org/whl/cu116\n",
        "!pip install numpy==1.25"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGwqxvb9y4m0"
      },
      "source": [
        "# Install requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KM9v8Y8xgycJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5b3104d-fbf9-4a92-f1bd-7e5c52b939d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///content/sd-scripts (from -r requirements.txt (line 42))\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting accelerate==0.30.0 (from -r requirements.txt (line 1))\n",
            "  Downloading accelerate-0.30.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting transformers==4.44.0 (from -r requirements.txt (line 2))\n",
            "  Downloading transformers-4.44.0-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting diffusers==0.25.0 (from diffusers[torch]==0.25.0->-r requirements.txt (line 3))\n",
            "  Downloading diffusers-0.25.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting ftfy==6.1.1 (from -r requirements.txt (line 4))\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting opencv-python==4.8.1.78 (from -r requirements.txt (line 6))\n",
            "  Downloading opencv_python-4.8.1.78-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "Collecting einops==0.7.0 (from -r requirements.txt (line 7))\n",
            "  Downloading einops-0.7.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting pytorch-lightning==1.9.0 (from -r requirements.txt (line 8))\n",
            "  Downloading pytorch_lightning-1.9.0-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting bitsandbytes==0.44.0 (from -r requirements.txt (line 9))\n",
            "  Downloading bitsandbytes-0.44.0-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\n",
            "Collecting prodigyopt==1.0 (from -r requirements.txt (line 10))\n",
            "  Downloading prodigyopt-1.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting lion-pytorch==0.0.6 (from -r requirements.txt (line 11))\n",
            "  Downloading lion_pytorch-0.0.6-py3-none-any.whl.metadata (620 bytes)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 12)) (2.18.0)\n",
            "Collecting safetensors==0.4.2 (from -r requirements.txt (line 13))\n",
            "  Downloading safetensors-0.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting altair==4.2.2 (from -r requirements.txt (line 15))\n",
            "  Downloading altair-4.2.2-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting easygui==0.98.3 (from -r requirements.txt (line 16))\n",
            "  Downloading easygui-0.98.3-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: toml==0.10.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 17)) (0.10.2)\n",
            "Collecting voluptuous==0.13.1 (from -r requirements.txt (line 18))\n",
            "  Downloading voluptuous-0.13.1-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting huggingface-hub==0.24.5 (from -r requirements.txt (line 19))\n",
            "  Downloading huggingface_hub-0.24.5-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: imagesize==1.4.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 21)) (1.4.1)\n",
            "Collecting rich==13.7.0 (from -r requirements.txt (line 40))\n",
            "  Downloading rich-13.7.0-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.30.0->-r requirements.txt (line 1)) (1.25.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.30.0->-r requirements.txt (line 1)) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate==0.30.0->-r requirements.txt (line 1)) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate==0.30.0->-r requirements.txt (line 1)) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.30.0->-r requirements.txt (line 1)) (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.0->-r requirements.txt (line 2)) (3.18.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.0->-r requirements.txt (line 2)) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.0->-r requirements.txt (line 2)) (2.32.3)\n",
            "Collecting tokenizers<0.20,>=0.19 (from transformers==4.44.0->-r requirements.txt (line 2))\n",
            "  Downloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.0->-r requirements.txt (line 2)) (4.67.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from diffusers==0.25.0->diffusers[torch]==0.25.0->-r requirements.txt (line 3)) (8.7.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from diffusers==0.25.0->diffusers[torch]==0.25.0->-r requirements.txt (line 3)) (11.2.1)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.11/dist-packages (from ftfy==6.1.1->-r requirements.txt (line 4)) (0.2.13)\n",
            "Requirement already satisfied: fsspec>2021.06.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning==1.9.0->-r requirements.txt (line 8)) (2025.3.2)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch-lightning==1.9.0->-r requirements.txt (line 8))\n",
            "  Downloading torchmetrics-1.7.3-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning==1.9.0->-r requirements.txt (line 8)) (4.14.0)\n",
            "Collecting lightning-utilities>=0.4.2 (from pytorch-lightning==1.9.0->-r requirements.txt (line 8))\n",
            "  Downloading lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.11/dist-packages (from altair==4.2.2->-r requirements.txt (line 15)) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair==4.2.2->-r requirements.txt (line 15)) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair==4.2.2->-r requirements.txt (line 15)) (4.24.0)\n",
            "Requirement already satisfied: pandas>=0.18 in /usr/local/lib/python3.11/dist-packages (from altair==4.2.2->-r requirements.txt (line 15)) (2.2.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.11/dist-packages (from altair==4.2.2->-r requirements.txt (line 15)) (0.12.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich==13.7.0->-r requirements.txt (line 40)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich==13.7.0->-r requirements.txt (line 40)) (2.19.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 12)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 12)) (1.73.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 12)) (3.8.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 12)) (5.29.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 12)) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 12)) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 12)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 12)) (3.1.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning==1.9.0->-r requirements.txt (line 8)) (3.11.15)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair==4.2.2->-r requirements.txt (line 15)) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair==4.2.2->-r requirements.txt (line 15)) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair==4.2.2->-r requirements.txt (line 15)) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair==4.2.2->-r requirements.txt (line 15)) (0.25.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich==13.7.0->-r requirements.txt (line 40)) (0.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.18->altair==4.2.2->-r requirements.txt (line 15)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.18->altair==4.2.2->-r requirements.txt (line 15)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.18->altair==4.2.2->-r requirements.txt (line 15)) (2025.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.30.0->-r requirements.txt (line 1)) (3.5)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.10.0->accelerate==0.30.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.10.0->accelerate==0.30.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.10.0->accelerate==0.30.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.10.0->accelerate==0.30.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.10.0->accelerate==0.30.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.10.0->accelerate==0.30.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.10.0->accelerate==0.30.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.10.0->accelerate==0.30.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.10.0->accelerate==0.30.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.30.0->-r requirements.txt (line 1)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.30.0->-r requirements.txt (line 1)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.30.0->-r requirements.txt (line 1)) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.10.0->accelerate==0.30.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.30.0->-r requirements.txt (line 1)) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.30.0->-r requirements.txt (line 1)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate==0.30.0->-r requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard->-r requirements.txt (line 12)) (3.0.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->diffusers==0.25.0->diffusers[torch]==0.25.0->-r requirements.txt (line 3)) (3.23.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.44.0->-r requirements.txt (line 2)) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.44.0->-r requirements.txt (line 2)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.44.0->-r requirements.txt (line 2)) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.44.0->-r requirements.txt (line 2)) (2025.6.15)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.0->-r requirements.txt (line 8)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.0->-r requirements.txt (line 8)) (1.3.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.0->-r requirements.txt (line 8)) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.0->-r requirements.txt (line 8)) (6.5.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.0->-r requirements.txt (line 8)) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.0->-r requirements.txt (line 8)) (1.20.1)\n",
            "Downloading accelerate-0.30.0-py3-none-any.whl (302 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.4/302.4 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.44.0-py3-none-any.whl (9.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m111.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading diffusers-0.25.0-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m99.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_python-4.8.1.78-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (61.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.7/61.7 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_lightning-1.9.0-py3-none-any.whl (825 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m825.8/825.8 kB\u001b[0m \u001b[31m66.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bitsandbytes-0.44.0-py3-none-manylinux_2_24_x86_64.whl (122.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.4/122.4 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading prodigyopt-1.0-py3-none-any.whl (5.5 kB)\n",
            "Downloading lion_pytorch-0.0.6-py3-none-any.whl (4.2 kB)\n",
            "Downloading safetensors-0.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m69.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading altair-4.2.2-py3-none-any.whl (813 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m813.6/813.6 kB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading easygui-0.98.3-py2.py3-none-any.whl (92 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.7/92.7 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading voluptuous-0.13.1-py3-none-any.whl (29 kB)\n",
            "Downloading huggingface_hub-0.24.5-py3-none-any.whl (417 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.5/417.5 kB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rich-13.7.0-py3-none-any.whl (240 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.6/240.6 kB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n",
            "Downloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m96.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m110.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m83.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m88.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.7.3-py3-none-any.whl (962 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m962.6/962.6 kB\u001b[0m \u001b[31m64.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: voluptuous, library, easygui, safetensors, prodigyopt, opencv-python, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, ftfy, einops, rich, nvidia-cusparse-cu12, nvidia-cudnn-cu12, huggingface-hub, tokenizers, nvidia-cusolver-cu12, diffusers, transformers, altair, torchmetrics, lion-pytorch, bitsandbytes, accelerate, pytorch-lightning\n",
            "  Running setup.py develop for library\n",
            "  Attempting uninstall: safetensors\n",
            "    Found existing installation: safetensors 0.5.3\n",
            "    Uninstalling safetensors-0.5.3:\n",
            "      Successfully uninstalled safetensors-0.5.3\n",
            "  Attempting uninstall: opencv-python\n",
            "    Found existing installation: opencv-python 4.11.0.86\n",
            "    Uninstalling opencv-python-4.11.0.86:\n",
            "      Successfully uninstalled opencv-python-4.11.0.86\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: einops\n",
            "    Found existing installation: einops 0.8.1\n",
            "    Uninstalling einops-0.8.1:\n",
            "      Successfully uninstalled einops-0.8.1\n",
            "  Attempting uninstall: rich\n",
            "    Found existing installation: rich 13.9.4\n",
            "    Uninstalling rich-13.9.4:\n",
            "      Successfully uninstalled rich-13.9.4\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.33.0\n",
            "    Uninstalling huggingface-hub-0.33.0:\n",
            "      Successfully uninstalled huggingface-hub-0.33.0\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.21.1\n",
            "    Uninstalling tokenizers-0.21.1:\n",
            "      Successfully uninstalled tokenizers-0.21.1\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: diffusers\n",
            "    Found existing installation: diffusers 0.33.1\n",
            "    Uninstalling diffusers-0.33.1:\n",
            "      Successfully uninstalled diffusers-0.33.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.52.4\n",
            "    Uninstalling transformers-4.52.4:\n",
            "      Successfully uninstalled transformers-4.52.4\n",
            "  Attempting uninstall: altair\n",
            "    Found existing installation: altair 5.5.0\n",
            "    Uninstalling altair-5.5.0:\n",
            "      Successfully uninstalled altair-5.5.0\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 1.8.1\n",
            "    Uninstalling accelerate-1.8.1:\n",
            "      Successfully uninstalled accelerate-1.8.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gradio 5.31.0 requires huggingface-hub>=0.28.1, but you have huggingface-hub 0.24.5 which is incompatible.\n",
            "pymc 5.23.0 requires rich>=13.7.1, but you have rich 13.7.0 which is incompatible.\n",
            "peft 0.15.2 requires huggingface_hub>=0.25.0, but you have huggingface-hub 0.24.5 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.25.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed accelerate-0.30.0 altair-4.2.2 bitsandbytes-0.44.0 diffusers-0.25.0 easygui-0.98.3 einops-0.7.0 ftfy-6.1.1 huggingface-hub-0.24.5 library-0.0.0 lightning-utilities-0.14.3 lion-pytorch-0.0.6 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 opencv-python-4.8.1.78 prodigyopt-1.0 pytorch-lightning-1.9.0 rich-13.7.0 safetensors-0.4.2 tokenizers-0.19.1 torchmetrics-1.7.3 transformers-4.44.0 voluptuous-0.13.1\n"
          ]
        }
      ],
      "source": [
        "!cd /content/sd-scripts && pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpyTI0X1y8V8"
      },
      "source": [
        "# Download sample LoRA models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Lx6QHRbVoELk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac5f5363-7784-4644-a34c-4c347ac32f70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-06-27 11:10:51--  https://civitai.com/api/download/models/29922\n",
            "Resolving civitai.com (civitai.com)... 104.22.18.237, 104.22.19.237, 172.67.12.143, ...\n",
            "Connecting to civitai.com (civitai.com)|104.22.18.237|:443... connected.\n",
            "HTTP request sent, awaiting response... 307 Temporary Redirect\n",
            "Location: https://civitai-delivery-worker-prod.5ac0637cfd0766c97916cefa3764fbdf.r2.cloudflarestorage.com/664133/model/weddingdressexv04.O79z.safetensors?X-Amz-Expires=86400&response-content-disposition=attachment%3B%20filename%3D%22WeddingDressEXv0.4.safetensors%22&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=e01358d793ad6966166af8b3064953ad/20250627/us-east-1/s3/aws4_request&X-Amz-Date=20250627T111051Z&X-Amz-SignedHeaders=host&X-Amz-Signature=0fb710617f1553dcafbf982a69e67b25b933d71a773d0c84e860ceb648a04b97 [following]\n",
            "--2025-06-27 11:10:51--  https://civitai-delivery-worker-prod.5ac0637cfd0766c97916cefa3764fbdf.r2.cloudflarestorage.com/664133/model/weddingdressexv04.O79z.safetensors?X-Amz-Expires=86400&response-content-disposition=attachment%3B%20filename%3D%22WeddingDressEXv0.4.safetensors%22&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=e01358d793ad6966166af8b3064953ad/20250627/us-east-1/s3/aws4_request&X-Amz-Date=20250627T111051Z&X-Amz-SignedHeaders=host&X-Amz-Signature=0fb710617f1553dcafbf982a69e67b25b933d71a773d0c84e860ceb648a04b97\n",
            "Resolving civitai-delivery-worker-prod.5ac0637cfd0766c97916cefa3764fbdf.r2.cloudflarestorage.com (civitai-delivery-worker-prod.5ac0637cfd0766c97916cefa3764fbdf.r2.cloudflarestorage.com)... 162.159.141.50, 172.66.1.46, 2606:4700:7::12e, ...\n",
            "Connecting to civitai-delivery-worker-prod.5ac0637cfd0766c97916cefa3764fbdf.r2.cloudflarestorage.com (civitai-delivery-worker-prod.5ac0637cfd0766c97916cefa3764fbdf.r2.cloudflarestorage.com)|162.159.141.50|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9549862 (9.1M) [application/octet-stream]\n",
            "Saving to: ‘wedding.safetensors’\n",
            "\n",
            "wedding.safetensors 100%[===================>]   9.11M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2025-06-27 11:10:52 (168 MB/s) - ‘wedding.safetensors’ saved [9549862/9549862]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#!wget https://civitai.com/api/download/models/89772 -O linhka.safetensors\n",
        "#!wget https://civitai.com/api/download/models/698249 -O aodai.safetensors\n",
        "!wget https://civitai.com/api/download/models/29922 -O wedding.safetensors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8pOdjcYzAQU"
      },
      "source": [
        "# Merge two LoRA models together"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "NUuDHEJHiHwD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b068f7f9-f6ab-4345-a53e-5a3a66a28f64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "2025-06-27 11:29:56.385418: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1751023796.408591   26125 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1751023796.416135   26125 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[2;36m2025-06-27 11:29:59\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m NumExpr defaulting to \u001b[1;36m2\u001b[0m threads.       \u001b]8;id=159790;file:///usr/local/lib/python3.11/dist-packages/numexpr/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=147803;file:///usr/local/lib/python3.11/dist-packages/numexpr/utils.py#164\u001b\\\u001b[2m164\u001b[0m\u001b]8;;\u001b\\\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "\u001b[2;36m2025-06-27 11:30:00\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m loading:                          \u001b]8;id=786953;file:///content/sd-scripts/networks/merge_lora.py\u001b\\\u001b[2mmerge_lora.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=878891;file:///content/sd-scripts/networks/merge_lora.py#124\u001b\\\u001b[2m124\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m                    \u001b[0m         \u001b[35m/content/\u001b[0m\u001b[95mlinhka.safetensors\u001b[0m       \u001b[2m                 \u001b[0m\n",
            "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m dim: \u001b[1m[\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1m]\u001b[0m, alpha: \u001b[1m[\u001b[0m\u001b[1;36m32.0\u001b[0m\u001b[1m]\u001b[0m          \u001b]8;id=92814;file:///content/sd-scripts/networks/merge_lora.py\u001b\\\u001b[2mmerge_lora.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=411630;file:///content/sd-scripts/networks/merge_lora.py#157\u001b\\\u001b[2m157\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m merging\u001b[33m...\u001b[0m                        \u001b]8;id=745139;file:///content/sd-scripts/networks/merge_lora.py\u001b\\\u001b[2mmerge_lora.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=987013;file:///content/sd-scripts/networks/merge_lora.py#160\u001b\\\u001b[2m160\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m2025-06-27 11:30:01\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m loading:                          \u001b]8;id=615648;file:///content/sd-scripts/networks/merge_lora.py\u001b\\\u001b[2mmerge_lora.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=444395;file:///content/sd-scripts/networks/merge_lora.py#124\u001b\\\u001b[2m124\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m                    \u001b[0m         \u001b[35m/content/\u001b[0m\u001b[95mwedding.safetensors\u001b[0m      \u001b[2m                 \u001b[0m\n",
            "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m dim: \u001b[1m[\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1m]\u001b[0m, alpha: \u001b[1m[\u001b[0m\u001b[1;36m4.0\u001b[0m\u001b[1m]\u001b[0m            \u001b]8;id=278338;file:///content/sd-scripts/networks/merge_lora.py\u001b\\\u001b[2mmerge_lora.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=738617;file:///content/sd-scripts/networks/merge_lora.py#157\u001b\\\u001b[2m157\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m merging\u001b[33m...\u001b[0m                        \u001b]8;id=855705;file:///content/sd-scripts/networks/merge_lora.py\u001b\\\u001b[2mmerge_lora.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=426970;file:///content/sd-scripts/networks/merge_lora.py#160\u001b\\\u001b[2m160\u001b[0m\u001b]8;;\u001b\\\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/sd-scripts/networks/merge_lora.py\", line 360, in <module>\n",
            "    merge(args)\n",
            "  File \"/content/sd-scripts/networks/merge_lora.py\", line 279, in merge\n",
            "    state_dict, metadata, v2 = merge_lora_models(args.models, args.ratios, merge_dtype, args.concat, args.shuffle)\n",
            "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/sd-scripts/networks/merge_lora.py\", line 181, in merge_lora_models\n",
            "    merged_sd[key].size() == lora_sd[key].size() or concat_dim is not None\n",
            "AssertionError: weights shape mismatch merging v1 and v2, different dims? / 重みのサイズが合いません。v1とv2、または次元数の異なるモデルはマージできません\n"
          ]
        }
      ],
      "source": [
        "!python sd-scripts/networks/merge_lora.py \\\n",
        "--save_precision fp16 \\\n",
        "--save_to /content/linhka_wedding.safetensors \\\n",
        "--models \\\n",
        "    /content/linhka.safetensors \\\n",
        "    /content/wedding.safetensors \\\n",
        "--ratios 0.5 0.5\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6TRWPmQzMxO"
      },
      "source": [
        "# Merge three LoRA models together"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "4dibQL-gx6sV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "270e04dc-ce55-422f-ebf0-b4cb228c3e05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "2025-06-27 10:37:36.194127: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1751020656.214453    6857 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1751020656.222858    6857 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[2;36m2025-06-27 10:37:38\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m NumExpr defaulting to \u001b[1;36m2\u001b[0m threads.       \u001b]8;id=63240;file:///usr/local/lib/python3.11/dist-packages/numexpr/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=102266;file:///usr/local/lib/python3.11/dist-packages/numexpr/utils.py#164\u001b\\\u001b[2m164\u001b[0m\u001b]8;;\u001b\\\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "\u001b[2;36m2025-06-27 10:37:39\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m loading:                          \u001b]8;id=370051;file:///content/sd-scripts/networks/merge_lora.py\u001b\\\u001b[2mmerge_lora.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=876387;file:///content/sd-scripts/networks/merge_lora.py#124\u001b\\\u001b[2m124\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m                    \u001b[0m         \u001b[35m/content/\u001b[0m\u001b[95mconcept-gropingbreast_pu\u001b[0m \u001b[2m                 \u001b[0m\n",
            "\u001b[2;36m                    \u001b[0m         \u001b[95mrged.safetensors\u001b[0m                  \u001b[2m                 \u001b[0m\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/sd-scripts/networks/merge_lora.py\", line 360, in <module>\n",
            "    merge(args)\n",
            "  File \"/content/sd-scripts/networks/merge_lora.py\", line 279, in merge\n",
            "    state_dict, metadata, v2 = merge_lora_models(args.models, args.ratios, merge_dtype, args.concat, args.shuffle)\n",
            "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/sd-scripts/networks/merge_lora.py\", line 125, in merge_lora_models\n",
            "    lora_sd, lora_metadata = load_state_dict(model, merge_dtype)\n",
            "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/sd-scripts/networks/merge_lora.py\", line 17, in load_state_dict\n",
            "    sd = load_file(file_name)\n",
            "         ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/safetensors/torch.py\", line 308, in load_file\n",
            "    with safe_open(filename, framework=\"pt\", device=device) as f:\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "safetensors_rust.SafetensorError: Error while deserializing header: HeaderTooLarge\n"
          ]
        }
      ],
      "source": [
        "!python sd-scripts/networks/merge_lora.py \\\n",
        "--save_precision fp16 \\\n",
        "--save_to /content/merge_3_pose.safetensor\\\n",
        "--models \\\n",
        "    /content/concept-gropingbreast.safetensors \\\n",
        "    /content/concept_1fingerselfie_illustriousXL.safetensors.safetensors \\\n",
        "    /content/concept_xgray.safetensors \\\n",
        "--ratios 0.3 0.3 0.3\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "subzCHO1zqjx"
      },
      "source": [
        "# Try upload your LoRA models and merge them\n",
        "You can drag and drop your LoRA models from your computer to the hard drive on google colab\n",
        "\n",
        "modify the scripts to use your uploaded LoRA models\n",
        "\n",
        "Enjoy!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "81mF0Z_Mzs0R"
      },
      "outputs": [],
      "source": [
        "# merge your LoRA models here\n",
        "# remove the comment # below\n",
        "# replace my-own-lora to your output LoRA model name\n",
        "# replace the uploaded-lora-01, uploaded-lora-02 to your uploaded LoRA model names\n",
        "\n",
        "# !python sd-scripts/networks/merge_lora.py \\\n",
        "# --save_precision fp16 \\\n",
        "# --save_to /content/my-own-lora.safetensors \\\n",
        "# --models \\\n",
        "#     /content/uploaded-lora-01.safetensors \\\n",
        "#     /content/uploaded-lora-02.safetensors \\\n",
        "# --ratios 0.5 0.5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbR9TEx9QGSi"
      },
      "source": [
        "# Patreon\n",
        "☕️ Please consider to support me in Patreon 🍻\n",
        "\n",
        "[https://www.patreon.com/lifeisboringsoprogramming](https://www.patreon.com/lifeisboringsoprogramming)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77b586a9",
        "outputId": "4cde6dd3-2aa4-4f72-ebca-ed38a145446a"
      },
      "source": [
        "from safetensors.torch import load_file\n",
        "import os\n",
        "\n",
        "def get_lora_dimension(file_path):\n",
        "    if not os.path.exists(file_path):\n",
        "        return f\"Error: File not found at {file_path}\"\n",
        "\n",
        "    try:\n",
        "        state_dict = load_file(file_path)\n",
        "\n",
        "        # Check metadata first (common in newer LoRA formats)\n",
        "        if '__metadata__' in state_dict:\n",
        "            metadata = state_dict['__metadata__']\n",
        "            if 'lora_dim' in metadata:\n",
        "                return int(metadata['lora_dim'])\n",
        "            if 'rank' in metadata: # Sometimes 'rank' is used instead of 'lora_dim'\n",
        "                return int(metadata['rank'])\n",
        "\n",
        "\n",
        "        # If not in metadata, look for tensor shapes (common in older formats)\n",
        "        for key, tensor in state_dict.items():\n",
        "            if 'lora_down' in key and tensor.ndim == 2:\n",
        "                # The dimension is typically the second dimension of the 'lora_down' weight\n",
        "                return tensor.shape[1]\n",
        "            elif 'lora_up' in key and tensor.ndim == 2:\n",
        "                 # The dimension is typically the first dimension of the 'lora_up' weight\n",
        "                return tensor.shape[0]\n",
        "\n",
        "        return \"Dimension information not found in the file.\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Error loading or inspecting file: {e}\"\n",
        "\n",
        "# Replace 'your_lora_model.safetensors' with the path to your LoRA file\n",
        "lora_file_path = '/content/linhka.safetensors' # Example from your notebook\n",
        "dimension = get_lora_dimension(lora_file_path)\n",
        "print(f\"The dimension (rank) of the LoRA model is: {dimension}\")\n",
        "\n",
        "lora_file_path = '/content/wedding.safetensors' # Example from your notebook\n",
        "dimension = get_lora_dimension(lora_file_path)\n",
        "print(f\"The dimension (rank) of the LoRA model is: {dimension}\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The dimension (rank) of the LoRA model is: 768\n",
            "The dimension (rank) of the LoRA model is: 768\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30310256",
        "outputId": "76d29058-6d3c-4a9d-86f2-44419b015886"
      },
      "source": [
        "%%execute cell --id NUuDHEJHiHwD"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "UsageError: Cell magic `%%execute` not found.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}